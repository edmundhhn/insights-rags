{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d86e49-7f1b-4a5b-8edc-59e4b02113ca",
   "metadata": {},
   "source": [
    "# Writing a Newsletter with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db533c6-b77a-46fd-b90c-387c552b01e4",
   "metadata": {},
   "source": [
    "> Summarizing the scraped insights articles for newsletter entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "be6e4498-0ce5-41af-b2f9-f7d62383ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.schema.document import Document\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFDirectoryLoader, PyPDFLoader\n",
    "from langchain_community.document_loaders import DataFrameLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b22e51-8a0f-426c-a459-13c1e6d3e08c",
   "metadata": {},
   "source": [
    "## Instantiate LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e6f632-6d6b-4ce9-bbb1-835fd6fbec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be97b80d-fbf6-4a54-ae29-224edf6ebccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "What do you call a fake noodle?\n",
      "\n",
      "An impasta.\n",
      "\n",
      "I hope that made you laugh! Do you want to hear another one?\n"
     ]
    }
   ],
   "source": [
    "# test the llm\n",
    "res = llm.invoke(\"Tell me a joke\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43044e7-dbe9-42bc-9d90-c7224f435247",
   "metadata": {},
   "source": [
    "## Get Best Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f388b77-2d95-4065-b794-92e27e4af2ab",
   "metadata": {},
   "source": [
    "In our first iteration of this method, we want to first use the LLM to identify the best three articles to write about and then summarize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774d39d-6c49-4a3d-99fd-6896cb543218",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "24f9b15f-1e3e-4c33-8be7-ba1e2a0a2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_prompt_china = \"\"\"Out of the following news headlines, select the three you believe are most significant to China. Return ONLY their corresponding indices.\n",
    "\n",
    "{titles}\n",
    "\"\"\"\n",
    "\n",
    "title_prompt_retail = \"\"\"Out of the following news headlines, select the three you believe are most significant to Walmart. Return ONLY their corresponding indices.\n",
    "\n",
    "{titles}\n",
    "\"\"\"\n",
    "\n",
    "title_prompt_market = \"\"\"Out of the following news headlines, select the three you believe are most significant to Tech Stocks. Return ONLY their corresponding indices.\n",
    "\n",
    "{titles}\n",
    "\"\"\"\n",
    "\n",
    "title_template = PromptTemplate(template=title_prompt, input_variables=[\"titles\"])\n",
    "\n",
    "stuff_prompt = \"\"\"\n",
    "Summarize the below article in 300 words for a newsletter. \n",
    "\n",
    "{text}\n",
    "\n",
    "NEWSLETTER ENTRY:\n",
    "\"\"\"\n",
    "\n",
    "stuff_prompt_template = PromptTemplate(template=stuff_prompt, input_variables=[\"text\"])\n",
    "\n",
    "map_prompt = \"\"\"\n",
    "Write a brief summary of the main points in the news article section.\n",
    "Make sure to include relevant supporting information and data.\n",
    "\n",
    "```{text}```\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])\n",
    "\n",
    "combine_prompt = \"\"\"\n",
    "Summarize the following text into an informative 500 word newsletter article. Use supporting data where possible, avoid bulletpoints.\n",
    "\n",
    "```{text}```\n",
    "\n",
    "NEWSLETTER ENTRY:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5d7d55bb-7cd3-45c3-864b-b3627d040d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_articles(df, topic):\n",
    "    \"\"\"\n",
    "    Uses LLM to select the articlse with the highest relevance and importance\n",
    "    \"\"\"\n",
    "    \n",
    "    # get titles\n",
    "    titles = \"\"\n",
    "    for i, title in df.title.items():\n",
    "        titles += f\"{i}. {title} \\n\"\n",
    "\n",
    "    # use llm to select best titles for that particular topic\n",
    "    if topic == \"china\":\n",
    "        title_template = PromptTemplate(template=title_prompt_china, input_variables=[\"titles\"])\n",
    "    elif topic == \"retail\":\n",
    "        title_template = PromptTemplate(template=title_prompt_retail, input_variables=[\"titles\"])\n",
    "    elif topic == \"market\":\n",
    "        title_template = PromptTemplate(template=title_prompt_market, input_variables=[\"titles\"])\n",
    "    else:\n",
    "        raise ValueError(\"provided topic not in list of predefined topics\")\n",
    "        \n",
    "    title_formatted_prompt = title_template.format(titles=titles)\n",
    "    response = llm.invoke(title_formatted_prompt)\n",
    "\n",
    "    article_selector = []\n",
    "    for char in response:\n",
    "        if char.isdigit():\n",
    "            article_selector.append(int(char))\n",
    "\n",
    "    \n",
    "    # ensure three are selected\n",
    "    if len(article_selector) < 3:\n",
    "        not_selected = list(set(df.index.to_list()) - set(article_selector))\n",
    "        article_selector += random.sample(not_selected, 3-len(article_selector))\n",
    "\n",
    "    elif len(article_selector) > 3:\n",
    "        article_selector = article_selector[:3]\n",
    "    \n",
    "    return article_selector\n",
    "\n",
    "# load chain\n",
    "chain = load_summarize_chain(llm, \n",
    "         chain_type=\"map_reduce\",\n",
    "         map_prompt = map_prompt_template,\n",
    "         combine_prompt = combine_prompt_template,\n",
    "         verbose=True\n",
    "        )\n",
    "\n",
    "stuff_chain = load_summarize_chain(llm, \n",
    "         chain_type=\"stuff\",\n",
    "         prompt = stuff_prompt_template,\n",
    "         #verbose=True\n",
    "        )\n",
    "\n",
    "def load_documents(df, article_ind):\n",
    "    \"\"\"\n",
    "    Load the selected documents from the dataframe\n",
    "    \"\"\"\n",
    "    df_trim = df.iloc[article_ind]\n",
    "    document_loader = DataFrameLoader(df_trim, page_content_column=\"content\")\n",
    "    return document_loader.load()\n",
    "\n",
    "def split_documents(documents: list[Document]):\n",
    "    \"\"\"\n",
    "    Split our documents as they are too long each\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=2000,\n",
    "        chunk_overlap=500,\n",
    "        #length_function=len,\n",
    "        #is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "def summarize_articles(topic:str):\n",
    "    \"\"\"\n",
    "    Takes the top three articles and summarizes them with LLM\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(f\"data/{topic}.csv\") \n",
    "    article_ind = select_best_articles(df, topic)\n",
    "    documents = load_documents(df, article_ind)\n",
    "    #split_docs = split_documents(documents)\n",
    "    #print(len(documents))\n",
    "    outputs = []\n",
    "    for document in documents:\n",
    "        #print(document)\n",
    "        output_summary = stuff_chain.invoke([document])\n",
    "        outputs.append(output_summary)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def summarize_all():\n",
    "    topics = [\"china\", \"retail\", \"market\"]\n",
    "    summaries_all = {}\n",
    "    for topic in topics:\n",
    "        topic_outputs = summarize_articles(topic)\n",
    "        summaries_all[topic] = topic_outputs\n",
    "        print(f\"{topic} SUMMARIES COMPLETE\")\n",
    "        \n",
    "    with open(\"data/summaries.pkl\", 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(summaries_all, outp, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return summaries_all\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a0b00c88-bea1-4ea7-99d0-3607e7919a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "china SUMMARIES COMPLETE\n",
      "retail SUMMARIES COMPLETE\n",
      "market SUMMARIES COMPLETE\n"
     ]
    }
   ],
   "source": [
    "outputs = summarize_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4f2f58df-1010-43b5-aa51-f2cb622d04d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"**Walmart Dominates US Online Grocery Market**\\n\\nAccording to a recent report, Walmart has become even more dominant in the US online grocery market, capturing 37% of the market share in Q2 2024. This represents a 1.5 percentage point increase from the same quarter last year and marks the company's highest share level to date.\\n\\nIn contrast, supermarkets saw a decline of 2.5 percentage points, finishing with 27.3% of the online grocery market. Walmart's sales share began gaining on supermarkets in early 2022, driven by factors such as inflation, declining personal savings rates, and rising interest rates.\\n\\nTarget also made moderate gains, increasing its share to 7% from 6% in Q2 2021. Brick Meets Click/Mercatus analysis suggests that Target's strong execution in filling pickup orders and a price gap halfway between supermarkets and Walmart contributed to its online grocery performance.\\n\\nThe report also highlights the growth of delivery sales, with mass formats (including Walmart) capturing nearly half of all delivery sales in Q2 2024. Pickup remains the dominant receiving method for online grocery sales, with a 45.5% share.\\n\\nAs online grocery sales continue to rise, Walmart's reputation for low prices and efficient execution has enabled it to deliver experiences that customers expect. With online grocery sales projected to reach almost $120 billion by 2028, companies will need to adapt to changing consumer behaviors and preferences.\",\n",
       " 'Here\\'s a summary of the article in 300 words for a newsletter:\\n\\n**Walmart Expands Immersive Shopping Experience for Back-to-College Season**\\n\\nWalmart is taking its immersive shopping experience to the next level with the launch of \"Your Dorm Your Way,\" the second phase of its \"Walmart Realm\" initiative. This virtual shopping environment, accessible on a dedicated website, allows customers to explore and shop five brand-new virtual dorm rooms inspired by social trends.\\n\\nEach of these 3D animated shops is curated by popular digital college creators and features a unique theme, such as a \"fantastical cotton candy and rainbow escape\" or a \"gamer-themed environment inspired by neon lights and arcades.\" Customers can click on items to add them to their shopping cart and participate in mini-games and surprise features.\\n\\nThe expansion of Walmart Realm is part of the company\\'s efforts to embrace virtual technologies and create immersive commerce experiences. The initiative, powered by Emperia, builds upon the metaverse platform and allows customers to explore and shop in a more engaging and interactive way.\\n\\nThis move is also part of Walmart\\'s broader strategy to expand its online presence through influencer partnerships and virtual commerce initiatives. The company has been testing immersive commerce in various online worlds, including Roblox and Unity, and has launched several programs to enable creators to monetize shoppable products from the retailer.\\n\\nWith the back-to-college season just around the corner, Walmart\\'s expanded immersive shopping experience is likely to appeal to students looking for a unique and engaging way to shop. As the retail landscape continues to evolve, it will be interesting to see how Walmart\\'s innovative approach to virtual commerce shapes the industry.',\n",
       " 'Here\\'s a summary of the article in 300 words for a newsletter:\\n\\n**Walmart Takes Steps to Reduce Food Waste with New Technology**\\n\\nWalmart is rolling out new technology to help store associates reduce food waste in their stores. The retail giant has implemented a program called Zero Depack, which uses organics recycler Denali\\'s technology to separate expired food from its packaging material with 97% accuracy. This allows associates to spend less time dealing with recycling and more time serving customers.\\n\\nWith Zero Depack, store associates simply toss expired food items into a receptacle, and the Denali technology does the rest. The separated food can then be converted into biosolids for various farming applications, such as compost or food for livestock.\\n\\nWalmart sees this initiative as part of its broader commitment to sustainability. In 2017, the company launched Project Gigaton, an effort to reduce one billion metric tons of carbon dioxide from its global value chain by 2030. The Zero Depack program is just one example of Walmart\\'s efforts to make meaningful changes and improve operations.\\n\\n\"Walmart facilities have a part to play in operating more sustainably,\" said R.J. Zanes, VP of facility services for Walmart U.S. \"By making sustainable choices, we can increase efficiencies, reduce costs, and improve experiences for our associates and customers.\"\\n\\nThis new technology is a positive step forward for Walmart, and we\\'re excited to see the impact it will have on reducing food waste in their stores!']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[output[\"output_text\"] for output in outputs[\"retail\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ab58b-6505-44e1-be6f-2fcd5be1227f",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2e3ca02e-c684-4fbb-bec4-dda6d0510b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused combined prompts\n",
    "\n",
    "combine_prompt = \"\"\"\n",
    "You will be given a series of texts below all from a single long article, delimited by triple backquotes.\n",
    "You are writing a newsletter section condensing out the important points in the article, each supported by a paragraph of around 200 words\n",
    "The target audience is company leadership, so be concise and rigorous.\n",
    "Final summary should be at around 500 words long and not only consist of bullet points.\n",
    "\n",
    "```{text}```\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    "\n",
    "combine_prompt = \"\"\"\n",
    "You will be given a series of texts below within the triple backquotes, all summaries of sections from the SAME article.\n",
    "You are a Walmart market researcher writing a newsletter section condensing out the important points in the article. Give sufficient support to these points.\n",
    "The target audience is executive leadership, final summary should be at around 500 words long and NOT USE bullet points.\n",
    "\n",
    "```{text}```\n",
    "\n",
    "NEWSLETTER ENTRY:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59432e1-00fe-450e-803a-1199ec879057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
